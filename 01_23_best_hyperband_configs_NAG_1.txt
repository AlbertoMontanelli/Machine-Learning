
 Best configuration after Hyperband n: 1 
Batch Size: 40
Validation Error: 1.340400365201821
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0
  alpha: 0
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 256
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 256
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 2 
Batch Size: 1
Validation Error: 1.4081179327248037
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0
  alpha: 0
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 128
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 128
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 3 
Batch Size: 1
Validation Error: 1.4228107070544502
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 1e-06
  alpha: 1
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 256
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 256
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 4 
Batch Size: 40
Validation Error: 1.4439852805851718
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 256
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 256
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 5 
Batch Size: 1
Validation Error: 1.4560720626400165
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 1e-06
  alpha: 1
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 128
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 128
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 6 
Batch Size: 1
Validation Error: 1.4566768076003225
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 1e-06
  alpha: 0.33
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 128
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 128
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 7 
Batch Size: 1
Validation Error: 1.4630640597447515
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 1e-06
  alpha: 0.66
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 128
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 128
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 8 
Batch Size: 1
Validation Error: 1.4658822666014104
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 1e-06
  alpha: 0.33
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 256
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 256
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 9 
Batch Size: 1
Validation Error: 1.4742690001649583
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 1e-06
  alpha: 0.66
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 256
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 256
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 10 
Batch Size: 1
Validation Error: 1.4813288995208744
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 1e-06
  alpha: 0
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 128
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 128
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 11 
Batch Size: 1
Validation Error: 1.5032973363916537
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 1e-06
  alpha: 0
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 256
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 256
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 12 
Batch Size: 40
Validation Error: 1.5435936542247308
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.33
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 256
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 256
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 13 
Batch Size: 1
Validation Error: 1.5478959235869965
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0
  alpha: 0
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 14 
Batch Size: 1
Validation Error: 1.548780716003923
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 1e-06
  alpha: 0.66
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 15 
Batch Size: 1
Validation Error: 1.5638185151355266
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0
  alpha: 0
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 16 
Batch Size: 40
Validation Error: 1.6630078387340013
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0
  alpha: 0
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 128
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 128
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 17 
Batch Size: 40
Validation Error: 1.6740775942914508
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 1e-06
  alpha: 0
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 128
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 128
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 18 
Batch Size: 1
Validation Error: 1.6817718975487026
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 1e-06
  alpha: 0.33
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 19 
Batch Size: 1
Validation Error: 1.6863534359226464
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 1e-06
  alpha: 0.66
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 20 
Batch Size: 1
Validation Error: 1.6913864377695593
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 1e-06
  alpha: 1
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 21 
Batch Size: 40
Validation Error: 1.7098378148235185
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 1e-06
  alpha: 0.66
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 128
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 128
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 22 
Batch Size: 40
Validation Error: 1.7163650771769863
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 1e-06
  alpha: 1
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 128
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 128
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 23 
Batch Size: 1
Validation Error: 1.7406215599004704
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 1e-06
  alpha: 0
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 24 
Batch Size: 40
Validation Error: 1.756747092260288
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 1e-06
  alpha: 0.33
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 128
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 128
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 25 
Batch Size: 40
Validation Error: 1.7741789302019508
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.66
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 256
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 256
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 26 
Batch Size: 40
Validation Error: 1.8540267976834293
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 128
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 128
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 27 
Batch Size: 1
Validation Error: 1.925024023587048
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0
  alpha: 0
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 28 
Batch Size: 40
Validation Error: 1.9435809920726286
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.33
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 128
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 128
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 29 
Batch Size: 1
Validation Error: 1.9483869376634533
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 1e-06
  alpha: 0
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Best configuration after Hyperband n: 30 
Batch Size: 40
Validation Error: 2.038728976730403
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 1
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 256
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 256
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------
