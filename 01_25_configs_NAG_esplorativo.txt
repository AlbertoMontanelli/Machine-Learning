
 Configuration n: 1 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750080628286614 +- 1.4433508762971559 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 2 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.748087502140311 +- 1.442093940749747 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 3 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695080974549702 +- 1.422991639402709 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 4 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.64814655335293 +- 1.4211407221035828 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 5 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174597947143937 +- 1.2074132352635767 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 6 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.351513420820336 +- 1.4149958047797835 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 7 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969246169777417 +- 1.0995679031303867 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 8 
Batch Size: 40
Smoothness: True
Validation Error MEE: 7.653546440354672 +- 1.0390743764643677 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 9 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750061800263284 +- 1.443338668133697 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 10 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.74634248879338 +- 1.4459051610915012 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 11 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695135932027583 +- 1.423009160090452 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 12 
Batch Size: 40
Smoothness: True
Validation Error MEE: 3.3067595378499233 +- 0.2697409059889547 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 13 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.17455156807721 +- 1.20740426718042 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 14 
Batch Size: 40
Smoothness: True
Validation Error MEE: 3.2621674845512487 +- 0.26402990834760415 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 15 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969223375084262 +- 1.099605585310691 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 16 
Batch Size: 40
Smoothness: True
Validation Error MEE: 3.065206464889133 +- 0.27296910334350555 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 17 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750075073987958 +- 1.4433454153715999 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 18 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750070430191764 +- 1.4433172705544195 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 19 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695105999391822 +- 1.423008680473783 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 20 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.680651143089728 +- 1.4297395544722165 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 21 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174633337751684 +- 1.20746940304275 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 22 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.216241211474776 +- 1.3147508934242984 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 23 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969300016836431 +- 1.0997512093153217 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 24 
Batch Size: 40
Smoothness: True
Validation Error MEE: 6.221802465761196 +- 1.0868847886271833 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 25 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750071441289183 +- 1.4433393424523002 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 26 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.749626440756682 +- 1.442899268201136 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 27 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695118816127364 +- 1.4229999614068314 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 28 
Batch Size: 40
Smoothness: True
Validation Error MEE: 3.337361003865238 +- 0.2711154629792775 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 29 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174623439950691 +- 1.2074559572458252 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 30 
Batch Size: 40
Smoothness: True
Validation Error MEE: 3.1344933941321336 +- 0.2790068315521217 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 31 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969286087085148 +- 1.0996541212703557 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 32 
Batch Size: 40
Smoothness: True
Validation Error MEE: 3.0672657555688394 +- 0.2723202362668984 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 33 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750070989119566 +- 1.4433337710559404 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 34 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750063523275314 +- 1.4433453644100211 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 35 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695077299770208 +- 1.4229863251457333 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 36 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.68650324065522 +- 1.4201558313351073 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 37 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174532276757015 +- 1.2074164293143426 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 38 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.229895642468929 +- 1.4110161657343432 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 39 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.9693149891854 +- 1.099716024544921 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 40 
Batch Size: 40
Smoothness: True
Validation Error MEE: 4.41426513598291 +- 0.6296338574191696 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 41 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750066629341058 +- 1.4433453053799574 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 42 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750138668992022 +- 1.4433339401184235 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 43 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695141310109578 +- 1.423044161230897 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 44 
Batch Size: 40
Smoothness: True
Validation Error MEE: 3.369196409288153 +- 0.29698450880782895 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 45 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.17460942601559 +- 1.2074711084273417 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 46 
Batch Size: 40
Smoothness: True
Validation Error MEE: 3.158420718408263 +- 0.2736862039662757 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 47 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969373841386458 +- 1.0997534627610335 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 48 
Batch Size: 40
Smoothness: True
Validation Error MEE: 3.0731080564395863 +- 0.26071970706733494 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 49 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750075026191762 +- 1.4433433259288349 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 50 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750030705009431 +- 1.4432940552920788 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 51 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695096802738238 +- 1.4229918566548279 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 52 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.694918714129702 +- 1.422995685178804 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 53 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174593756431351 +- 1.2074476161897425 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 54 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174607469484368 +- 1.207463980765069 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 55 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969307449711954 +- 1.0997050087389713 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 56 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969915212832484 +- 1.1001114480162935 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 57 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750072323665396 +- 1.4433400061057193 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 58 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750048429934937 +- 1.4433263001461805 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 59 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695100808704925 +- 1.4230011231130513 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 60 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.692143755632106 +- 1.42073639860731 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 61 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174614675483863 +- 1.2074709727132151 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 62 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.577220711721328 +- 1.3318463802569804 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 63 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.96930330384382 +- 1.0996856721504868 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 64 
Batch Size: 40
Smoothness: True
Validation Error MEE: 4.638685626155614 +- 3.364442657044343 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 65 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750071121465549 +- 1.443340139857049 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 66 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750098517187334 +- 1.4433663646041581 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 67 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695097005177619 +- 1.4229843441143106 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 68 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695121892214726 +- 1.4230047339863512 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 69 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174594344563761 +- 1.2074395650441931 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 70 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174668778532753 +- 1.2075231198601433 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 71 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969298019518193 +- 1.099680485551544 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 72 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969469532458296 +- 1.0998794600225783 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 73 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750072310691474 +- 1.4433424779904187 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 74 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750079751169178 +- 1.4433468780528147 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 75 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.69510605637058 +- 1.4229948884402794 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 76 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695094154671082 +- 1.4229960556014394 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 77 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174613608878866 +- 1.207452616142452 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 78 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.627926525193136 +- 1.4196076969875024 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 79 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969304153591143 +- 1.099689709693311 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 80 
Batch Size: 40
Smoothness: True
Validation Error MEE: 4.69520925666912 +- 3.689419083072143 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 81 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750071472292834 +- 1.4433411594097914 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 82 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750066895034669 +- 1.443342514304669 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 83 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695090093727327 +- 1.4229892925124064 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 84 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.6952077707977 +- 1.4231091308951531 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 85 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174582849979071 +- 1.207411273731347 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 86 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174686529329806 +- 1.2074738380181593 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 87 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969331538861386 +- 1.0997062857816995 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 88 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969611967839116 +- 1.0997969561721228 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 89 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750072004416955 +- 1.4433397435742001 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 90 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.75007312011369 +- 1.4433418001976615 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 91 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695096476847334 +- 1.4229850555382413 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 92 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695118130477988 +- 1.4232523125753238 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 93 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.17459064080138 +- 1.2074473919152424 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 94 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174917747864269 +- 1.207592943481378 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 95 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969284213684556 +- 1.0996757929112564 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 96 
Batch Size: 40
Smoothness: True
Validation Error MEE: 4.652120708371575 +- 3.707315116643826 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 16
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 97 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750068804962579 +- 1.4433385845457323 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 98 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750084593917371 +- 1.4433437384515937 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 99 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695087821007712 +- 1.4229773085033153 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 100 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.69494267794054 +- 1.4228735538310475 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 101 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174549791977318 +- 1.2073966458470387 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 102 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174733446024327 +- 1.2074406894259302 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 103 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969254914500222 +- 1.0996555106512753 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 104 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969582939991108 +- 1.0999727533739878 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 105 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750068592121002 +- 1.4433396034771768 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 106 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750080331201193 +- 1.443329947603981 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 107 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695100606253206 +- 1.4229954475454116 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 108 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.694987181264414 +- 1.422949248958134 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 109 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.17458713001693 +- 1.2074316693054439 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 110 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.17485625878651 +- 1.2074681064857726 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 111 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969326091953771 +- 1.0997217304267985 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 112 
Batch Size: 40
Smoothness: True
Validation Error MEE: 7.309388891646132 +- 4.040859098274368 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 113 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750072605272468 +- 1.4433387291393491 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 114 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750083746431262 +- 1.4433402669025754 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 115 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.69509778591664 +- 1.422995652891397 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 116 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695105275090778 +- 1.4229158708738339 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 117 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174596062755343 +- 1.2074406914887912 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 118 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174629300428386 +- 1.2074468702496166 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 119 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969297015939231 +- 1.0996851390668785 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 120 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969613113484396 +- 1.099820406772278 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 121 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750073233992241 +- 1.4433418134695255 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 122 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750072790117523 +- 1.4433543365390908 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 123 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695091502197922 +- 1.4229744699505633 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 124 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695115732005267 +- 1.4230493698959907 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 125 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174602529599257 +- 1.207446058968261 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 126 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.17497221894421 +- 1.2076422962031956 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 127 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969297518671086 +- 1.0996950174731137 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 128 
Batch Size: 40
Smoothness: True
Validation Error MEE: 5.827573699470124 +- 3.7483095411382754 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 129 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750074638477528 +- 1.4433450245713342 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 130 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750079815442172 +- 1.4433482122967833 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 131 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695074060685112 +- 1.4229709012199887 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 132 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695124340049466 +- 1.422927969764446 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 133 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174606780397758 +- 1.2074380303320646 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 134 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.17465527869193 +- 1.2074555972664 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 135 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969277338520863 +- 1.0996720098561164 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 136 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969464408571422 +- 1.0996173401796174 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 137 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750073794327283 +- 1.4433429720858435 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 138 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750060642545197 +- 1.4433171755275211 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 139 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695093330109056 +- 1.4229935818223243 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 140 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.69524268299925 +- 1.4231091812208665 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 141 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174584003954894 +- 1.207435742443224 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 142 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174737168357463 +- 1.207445107094499 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 143 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969292744029255 +- 1.099668221862269 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 144 
Batch Size: 40
Smoothness: True
Validation Error MEE: 4.64164789752467 +- 3.36266237551949 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 32
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 145 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750068148113542 +- 1.443338742905545 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 146 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750060760983851 +- 1.4433315402424396 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 147 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695091865833565 +- 1.42297917843383 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 148 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.694940723754462 +- 1.4229249764156726 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 149 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.17457816434063 +- 1.207432005368143 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 150 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.17476091703568 +- 1.2075437763080592 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 151 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969310132038824 +- 1.0996944845790524 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 152 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969748077955511 +- 1.0998714752732488 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 16
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 153 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750070839248973 +- 1.4433393119497053 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 154 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750048530825556 +- 1.4433220332083079 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 155 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695088054162216 +- 1.4229908917794356 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 156 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.694829985682862 +- 1.4229737126741118 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 157 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.17460911388559 +- 1.2074505144602614 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 158 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174958658650336 +- 1.207498578700546 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 159 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969308925807777 +- 1.09970022001782 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 160 
Batch Size: 40
Smoothness: True
Validation Error MEE: 4.632704730130653 +- 3.7177142190166985 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 16
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 16
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 161 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750071671708957 +- 1.443339676279923 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 162 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.7500800930712 +- 1.443342807122813 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 163 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.69508538892355 +- 1.4230070533936132 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 164 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695188545335649 +- 1.423042757108981 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 165 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174622856605232 +- 1.2074545474037863 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 166 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174787144232107 +- 1.2076022217372515 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 167 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969298446813193 +- 1.0996844801709058 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 168 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969560187703202 +- 1.0997899596412857 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 32
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 169 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750066742497278 +- 1.4433365607624724 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 170 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750072307095731 +- 1.4433545331508886 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 171 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.69508981938804 +- 1.4229759817409444 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 172 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695244067702342 +- 1.4230388693465172 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 173 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174577916947982 +- 1.2074288454524396 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 174 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.175156283678884 +- 1.2076609151732247 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 175 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969294050417421 +- 1.0996810073453862 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 176 
Batch Size: 40
Smoothness: True
Validation Error MEE: 4.537221854894426 +- 3.1864650293774393 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 32
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 32
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 177 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750072885215369 +- 1.4433420661356524 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 178 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750088083528171 +- 1.4433496522989435 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 179 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695099395755102 +- 1.4229901335717579 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 180 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695097929367886 +- 1.4230029719910067 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 181 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174593099879308 +- 1.2074538552923788 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 182 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.17477748246786 +- 1.2075224313773738 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 183 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969285894076737 +- 1.099682534966522 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 184 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.969489309423416 +- 1.0997772603656477 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 64
    activation_function: tanh
    d_activation_function: d_tanh
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 185 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.7500739587411 +- 1.4433413559755945 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 186 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.750070425333794 +- 1.4433326800947432 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 187 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695108937841663 +- 1.4230009424697345 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 188 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.695259732062343 +- 1.4231191117072117 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0004
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 189 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.174603547920507 +- 1.2074398554963084 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 190 
Batch Size: 40
Smoothness: True
Validation Error MEE: 10.175007508643864 +- 1.2076553684689049 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.0007
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 191 
Batch Size: 40
Smoothness: True
Validation Error MEE: 9.96929652582026 +- 1.099661465721324 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------

 Configuration n: 192 
Batch Size: 40
Smoothness: True
Validation Error MEE: 5.83093682217205 +- 3.7463155319973604 
NN Details:
=== Neural Network Details ===

Regularizer Configuration:
  Lambda: 0.0001
  alpha: 0.5
  reg_type: elastic

Layers Configuration:
    Layer 1:
    dim_prev_layer: 12
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 2:
    dim_prev_layer: 64
    dim_layer: 64
    activation_function: leaky_relu
    d_activation_function: d_leaky_relu
    Layer 3:
    dim_prev_layer: 64
    dim_layer: 3
    activation_function: linear
    d_activation_function: d_linear

Optimizers Configuration:
  Optimizer 1:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 2:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None
  Optimizer 3:
    opt_type: NAG
    learning_rate: 0.001
    momentum: 0.9
    beta_1: None
    beta_2: None
    epsilon: None

--------------------------------------------------
